import gensim
import sys

from gensim.test.utils import common_texts, get_tmpfile, datapath
from gensim.models import Word2Vec

DATA_DIR = "../data/"

def main():

	google = DATA_DIR + "GoogleNews-vectors-negative300.bin"

	# Load Google's pre-trained Word2Vec model.
	model = gensim.models.KeyedVectors.load_word2vec_format(google, binary=True)

	# some tests
	v = model['king']
	u = model['man']
	vPrime = model['queen']
	uPrime = model['woman']

	ourModel = u + v - uPrime
	Mikolov = v - u + uPrime

	print("Words similar to the z vector generated by our method:")
	print(model.wv.similar_by_vector(ourModel, topn=10, restrict_vocab=None))
	print ("---------------------------------------------------------------")
	print("Words similar to the z vector generated by Mikolov's method:")
	print(model.wv.similar_by_vector(Mikolov, topn=10, restrict_vocab=None))
	print("----------------------------------------------------------------")
	print(model.wv.similar_by_word("king", topn=10, restrict_vocab=None))

	# TODOS
	# Add functions for cosine distance and euclidean distance
	# Print euclidean distance between our model and woman
	# Print euclidean distance between Mikolov model and woman
	# Check if vectors are normalized - sum squares of each vector, if sums to 1 then normalized


if __name__ == '__main__':
	main()